{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NbkyQ1tSj0wy3MxJXuQLJ8h_SYqOwSFW",
      "authorship_tag": "ABX9TyOASPlbZYhUdldXK6v1ZcDM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeonui-0626/lstm/blob/main/lstm_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHPh2Wj5llSz"
      },
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from matplotlib import pyplot\n",
        "from datetime import datetime\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "#import keras.backend.tensorflow_backend as K"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVfED_m2nLw0",
        "outputId": "6c07986f-4a53-4340-f2d8-3593b2e970b5"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2sBFb7xluOm"
      },
      "source": [
        "#%%time\n",
        "data = pd.read_csv('/content/gdrive/MyDrive/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv', index_col=2)\n",
        "data.loc[data['Label']=='Benign','Label'] = 0\n",
        "data.loc[data['Label']=='Bot','Label'] = 1\n",
        "data.index.name = 'date'\n",
        "\n",
        "# 결측치  저리\n",
        "data = data.replace([np.inf, -np.inf], np.nan)\n",
        "data['Flow Byts/s'].fillna(0.0,inplace=True)\n",
        "data['Flow Pkts/s'].fillna(0.0,inplace=True)\n",
        "values = data.values\n",
        "values = values.astype('float64')\n",
        " \n",
        "# 정규화\n",
        "scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
        "scaled = scaler.fit_transform(values)\n",
        "label = scaled[:,-1]\n",
        "\n",
        "# def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "#     n_vars = 1 if type(data) is list else data.shape[1]\n",
        "#     df = DataFrame(data)\n",
        "#     cols, names = list(), list()\n",
        "#     # input sequence (t-n, ... t-1)\n",
        "#     for i in range(n_in, 0, -1):\n",
        "#         cols.append(df.shift(i))\n",
        "#         names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "#     # forecast sequence (t, t+1, ... t+n)\n",
        "#     for i in range(0, n_out):\n",
        "#         cols.append(df.shift(-i))\n",
        "#         if i == 0:\n",
        "#             names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "#         else:\n",
        "#             names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "#     # put it all together\n",
        "#     agg = concat(cols, axis=1)\n",
        "#     agg.columns = names\n",
        "#     # drop rows with NaN values\n",
        "#     if dropnan:\n",
        "#         agg.dropna(inplace=True)\n",
        "#     return agg\n",
        "# timesteps = 1\n",
        "# reframed = series_to_supervised(scaled,timesteps,1)\n",
        "# values = reframed.values\n",
        "\n",
        "timesteps = 1\n",
        "train_x, test_x, train_y, test_y = train_test_split(scaled, label, test_size=0.3, random_state=1004)\n",
        "\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "train_x = train_x.reshape((train_x.shape[0], timesteps, train_x.shape[1]))\n",
        "test_x = test_x.reshape((test_x.shape[0], timesteps, test_x.shape[1]))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLhiGl8el0jB"
      },
      "source": [
        "%%time\n",
        "print(\"시작\")\n",
        "# model\n",
        "#with K.tf.device('/gpu:0'):\n",
        "timesteps = 1\n",
        "feature = train_x.shape[2]\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(timesteps, feature)))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation='softmax'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(train_x,train_y, epochs=10, batch_size=100, validation_data=(test_x, test_y), verbose=1, shuffle=False)\n",
        "print('\\n## training loss and acc ##')\n",
        "print(history.history['loss'],end='\\n\\n')\n",
        "\n",
        "yhat = model.predict(test_x)\n",
        "print(\"총 예측수 :\",yhat.shape)\n",
        "print(\"Bot 탐지수 :\",yhat[yhat==1].shape)\n",
        "print(\"정상 탐지수 :\",yhat[yhat==0].shape)\n",
        "\n",
        "del [[model, history]]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}